# Elasticsearch

## 索引操作

### 创建索引并查看



```
PUT /customer
GET /_cat/indices?v
```

![image-20220220132416409](https://raw.githubusercontent.com/a1254898873/images/master/image-20220220132416409.png)



### 删除索引并查看



```
DELETE /customer
GET /_cat/indices?v
```

![image-20220220132508992](https://raw.githubusercontent.com/a1254898873/images/master/image-20220220132508992.png)





### 索引文档

保存一个数据，保存在哪个索引的哪个类型下，指定用哪个唯一标识PUT customer/external/1； 在 customer 索引下的 external 类型下保存 1 号数据为

```
PUT customer/external/1
```

- PUT 和 POST 都可以；
- POST 新增。如果不指定id，会自动生成 id。指定 id 就会修改这个数据，并新增版本号；
- PUT 可以新增也可以修改。PUT 必须指定 id；由于 PUT 需要指定 id，我们一般都用来做修改；





### 查询文档



```
GET customer/external/1
```

```
结果:
{
    "_index": "customer",	//在哪个索引
    "_type": "external",	//在哪个类型
    "_id": "1",				//记录id
    "_version": 4,			//版本号
    "_seq_no": 5,			//并发控制字段,每次更新就会+1,用来做乐观锁
    "_primary_term": 1,		//同上,主分片重新分配,如重启,就会变化
    "found": true,			//表示找到了数据
    "_source": {			//数据内容
        "name": "lohn Doe"
    }
}
```





### 更新文档

| 更新操作                                          | 参数或结论                                                   |
| :------------------------------------------------ | ------------------------------------------------------------ |
| POST  customer/external/1/_update                 | {      "doc": {           "name": "Jane Doe",           "age": 20      } } |
| 或者POST  customer/external/1                     | { "name": "John Nash2" }                                     |
| 或者PUT  customer/external/1                      | { "name": "John Nash3" }                                     |
| 不同                                              | POST 操作会对比源文档数据,如果相同不会有什么操作,文档 version 、_seq_no 不增加; PUT 操作总会将数据重新保存并增加 version 版本; 带 _update 对比元数据如果一样就不进行任何操作。 |
| 看场景                                            | 对于大并发更新,不带update; 对于大并发查询偶尔更新,带update;对比更新,重新计算分配规则。 |
| 更新同时增加属性 POST customer/external/1/_update | {      "doc": {           "name": "Jane Doe",           "age": 20      } } |
| 更新同时增加属性 PUT&POST customer/external/1     | {      "name": "John Nash2",      "age": 40 }                |





### 删除文档

| 删除类型 | 方法或路径参数             |
| -------- | -------------------------- |
| 删除文档 | DELETE customer/external/1 |
| 删除索引 | DELETE customer            |









## 查询





### 查询方式

ES 支持两种基本方式检索：

- 一个是通过使用 REST request URI 发送搜索参数(uri+检索参数)
- 另一个是通过使用 REST requestbody 来发送它们(uri+请求体)





1、 REST request URI 

| 请求或返回                                   | 解释                                                     |
| -------------------------------------------- | -------------------------------------------------------- |
| GET bank/_search                             | 检索 bank 下所有信息,包括 type 和 docs                   |
| GET bank/_search?q=*&sort=account_number:asc | 请求参数方式检索                                         |
| 响应结果解释：                               |                                                          |
| took                                         | Elasticsearch执行搜索的时间(臺秒)                        |
| time_out                                     | 告诉我们搜索是否超时                                     |
| _shards                                      | 告诉我们多少个分片被搜索了,以及统计了成功/失败的搜索分片 |
| hits                                         | 搜索结果                                                 |
| hits.total                                   | 搜索结果                                                 |
| hits.hits                                    | 实际的搜索结果数组(默认为前10的文档)                     |
| sort                                         | 结果的排序 key (键) (没有则按 score 排序)                |
| score 和 max_score                           | 相关性得分和最高得分(全文检索用)                         |


![在这里插入图片描述](https://raw.githubusercontent.com/a1254898873/images/master/172873888b1b514b%7Etplv-t2oaga2asx-watermark.awebp)





2、uri+请求体 进行检索

```
GET /bank/_search
{
  "query": {
    "match_all": {}
  },
  "sort": [
    {
      "account_number": "asc"
    },
    {
      "balance": "desc"
    }
  ]
}
```

HTTP 客户端工具(POSTMAN)，get 请求不能携带请求体，我们变为 post 也是一样的我们 POST 一个 JSON 风格的查询请求体到_search APl。需要了解，一旦搜索的结果被返回， Elasticsearch 就完成了这次请求，并且不会维护任何服务端的资源或者结果的 cursor (游标)

![在这里插入图片描述](https://raw.githubusercontent.com/a1254898873/images/master/17287388996ae4e8%7Etplv-t2oaga2asx-watermark.awebp)









### Query DSL

Elastisearch 提供了一个可以执行查询的 Json 风格的 DSl (domain-specific language 领域特定语言) 。这个被称为Query DSL

1、match【匹配查询】

```
GET /bank/_search
{
  "query": {
    "match": {
      "address": "Kings"
    }
  }
}
```

![在这里插入图片描述](https://raw.githubusercontent.com/a1254898873/images/master/17287388c2cfc56b%7Etplv-t2oaga2asx-watermark.awebp)





```
GET /bank/_search
{
  "query": {
    "match": {
      "address": "Mill Lane"
    }
  }
}
```

最终查询出 address 中包含 Mill 或者 Lane 或者 Mill Lane 的所有记录,并给出相关性得分

![在这里插入图片描述](https://raw.githubusercontent.com/a1254898873/images/master/17287388ce48a5d3%7Etplv-t2oaga2asx-watermark.awebp)





2、match_phrase 【短语匹配】

将需要匹配的值当成一个整体单词(不分词)进行检索

```
GET /bank/_search
{
  "query": {
    "match_phrase": {
      "address": "mill road"
    }
  }
}
```

![在这里插入图片描述](https://raw.githubusercontent.com/a1254898873/images/master/17287388f3134df6%7Etplv-t2oaga2asx-watermark.awebp)





3、multi_match 【多字段匹配】

```
GET /bank/_search
{
  "query": {
    "multi_match": {
      "query": "mill",
      "fields": ["address","state"]
    }
  }
}
```

![在这里插入图片描述](https://raw.githubusercontent.com/a1254898873/images/master/17287388f322ff7a%7Etplv-t2oaga2asx-watermark.awebp)





4、组合搜索

使用bool来进行组合，must表示同时满足，例如搜索address字段中同时包含mill和lane的文档；

```
GET /bank/_search
{
  "query": {
    "bool": {
      "must": [
        { "match": { "address": "mill" } },
        { "match": { "address": "lane" } }
      ]
    }
  }
}
```

![img](https://raw.githubusercontent.com/a1254898873/images/master/17154c9ce2d90dda%7Etplv-t2oaga2asx-watermark.awebp)



should表示满足其中任意一个，搜索address字段中包含mill或者lane的文档；

```
GET /bank/_search
{
  "query": {
    "bool": {
      "should": [
        { "match": { "address": "mill" } },
        { "match": { "address": "lane" } }
      ]
    }
  }
}
```

![img](https://raw.githubusercontent.com/a1254898873/images/master/17154c9cf5b52fc9%7Etplv-t2oaga2asx-watermark.awebp)



must_not表示同时不满足，例如搜索address字段中不包含mill且不包含lane的文档；

```
GET /bank/_search
{
  "query": {
    "bool": {
      "must_not": [
        { "match": { "address": "mill" } },
        { "match": { "address": "lane" } }
      ]
    }
  }
}
```

![img](https://raw.githubusercontent.com/a1254898873/images/master/17154c9cee6ae7f4%7Etplv-t2oaga2asx-watermark.awebp)









## 与springboot结合

### 配置



application.properties

```
spring.data.elasticsearch.repositories.enabled = true
spring.elasticsearch.rest.uris=localhost:9200
```

ElasticsearchRestTemplate配置

```
@Configuration
public class ElasticsearchRestTemplateConfig extends AbstractElasticsearchConfiguration {
    @Value("${spring.elasticsearch.rest.uris}")
    private String uris;

    @Override
    public RestHighLevelClient elasticsearchClient() {
        ClientConfiguration configuration = ClientConfiguration.builder()
                .connectedTo(uris)
                .build();
        return RestClients.create(configuration).rest();
    }
}
```





### Model

​		我这里定义了一个员工类，并使用@Document定义员工类关联的index索引、typeso因类型，shards主分区，replicas副分区。

　　在@Document中有个属性是createIndex，表示当索引不存在时，操作这个对象会默认创建索引，默认为true。如果你的索引设置比较多，就把createIndex设置为false，再通过其他接口手动触发创建索引操作。

　　@Id 表示索引的主键

　　@Field 用来描述字段的ES数据类型，是否分词等配置，等于Mapping描述

```
/**
 * 员工对象
 * <p>
 * 注解：@Document用来声明Java对象与ElasticSearch索引的关系
 * indexName 索引名称
 * type      索引类型
 * shards    主分区数量，默认5
 * replicas  副本分区数量，默认1
 * createIndex 索引不存在时，是否自动创建索引，默认true*/
@Getter
@Setter
@NoArgsConstructor
@Accessors(chain = true)
@Document(indexName = "employee_index", type = "employee_type", shards = 1, replicas = 0，createIndex = true)
public class EmployeeBean {

    @Id
    private String id;

    /**
     * 员工编码
     */
    @Field(type = FieldType.Keyword)
    private String studentCode;

    /**
     * 员工姓名
     */
    @Field(type = FieldType.Keyword)
    private String name;

    /**
     * 员工简历
     */
    @Field(type = FieldType.Text, analyzer = "ik_max_word")
    private String desc;

    /**
     * 员工住址
     */
    @Field(type = FieldType.Text, analyzer = "ik_max_word")
    private Integer type;

    /**
     * 手机号码
     */
    @Field(type = FieldType.Keyword)
    private String mobile;

}
```



### Repository接口



```
@Component
public interface EmployeeRepository extends ElasticsearchRepository<EmployeeBean, String> {


}
```

我们在操作索引和数据时，需要引用这2个类

```
    @Autowired
    private ElasticsearchRestTemplate restTemplate;
    @Autowired
    private EmployeeRepository repository;
```



### 索引操作



1、判断索引是否存在

```
/**
     * 判断索引是否存在
     * @return boolean
     */
    public boolean indexExists() {
        return restTemplate.indexExists(EmployeeBean.class);
    }

    /**
     * 判断索引是否存在
     * @param indexName 索引名称
     * @return boolean
     */
    public boolean indexExists(String indexName) {
        return restTemplate.indexExists(indexName);
    }
```



2、创建索引

```
/**
     * 创建索引（推荐使用：因为Java对象已经通过注解描述了Setting和Mapping）
     * @return boolean
     */
    public boolean indexCreate() {
        return restTemplate.createIndex(EmployeeBean.class);
    }

    /**
     * 创建索引
     * @param indexName 索引名称
     * @return boolean
     */
    public boolean indexCreate(String indexName) {
        return restTemplate.createIndex(indexName);
    }
```



3、删除索引

```
/**
     * 索引删除
     * @param indexName 索引名称
     * @return boolean
     */
    public boolean indexDelete(String indexName) {
        return restTemplate.deleteIndex(indexName);
    }
```



### 数据操作

1、新增数据

```
/**
     * 新增数据
     * @param bean 数据对象
     */
    public void save(EmployeeBean bean) {
        repository.save(bean);
    }

    /**
     * 批量新增数据
     * @param list 数据集合
     */
    public void saveAll(List<EmployeeBean> list) {
        repository.saveAll(list);
    }
```



2、修改数据



```
/**
     * 修改数据
     * @param indexName 索引名称
     * @param type      索引类型
     * @param bean 修改数据对象，ID不能为空
     */
    public void update(String indexName, String type, EmployeeBean bean) {
        UpdateRequest updateRequest = new UpdateRequest();
        updateRequest.retryOnConflict(1);//冲突重试
        updateRequest.doc(JSONUtil.toJsonStr(bean), XContentType.JSON);
        updateRequest.routing(bean.getId());//默认是_id来路由的，用来路由到不同的shard，会对这个值做hash，然后映射到shard。所以分片
        UpdateQuery query = new UpdateQueryBuilder().withIndexName(indexName).withType(type).withId(bean.getId())
                .withDoUpsert(true)//不加默认false。true表示更新时不存在就插入
                .withClass(EmployeeBean.class).withUpdateRequest(updateRequest).build();
        UpdateResponse updateResponse = restTemplate.update(query);
    }
```





3、删除数据



```
/**
     * 根据ID，删除数据
     * @param id 数据ID
     */public void deleteById(String id) {
        repository.deleteById(id);
    }

    /**
     * 根据对象删除数据，主键ID不能为空
     * @param bean 对象
     */public void deleteByBean(EmployeeBean bean) {
        repository.delete(bean);
    }

    /**
     * 根据对象集合，批量删除
     * @param beanList 对象集合
     */public void deleteAll(List<EmployeeBean> beanList) {
        repository.deleteAll(beanList);
    }

    /**
     * 删除所有
     */public void deleteAll() {
        repository.deleteAll();
    }
    
    /**
     * 根据条件，自定义删除（在setQuery中的条件，可以根据需求自由拼接各种参数，与查询方法一样）
     * @param indexName 索引
     * @param type      索引类型
     */public void delete(String indexName, String type) {
        DeleteQuery deleteQuery = new DeleteQuery();
        deleteQuery.setIndex(indexName);
        deleteQuery.setType(type);//建index没配置就是类名全小写
        deleteQuery.setQuery(new BoolQueryBuilder().must(QueryBuilders.termQuery("mobile","13526568454")));
        restTemplate.delete(deleteQuery);
    }
```



### 查询操作



```
/**
     * 数据查询，返回List
     * @param field 查询字段
     * @param value 查询值
     * @return List<EmployeeBean>
     */
    @Override
    public List<EmployeeBean> queryMatchList(String field, String value) {
        MatchQueryBuilder builder = QueryBuilders.matchQuery(field, value);
        SearchQuery searchQuery = new NativeSearchQuery(builder);
        return restTemplate.queryForList(searchQuery, EmployeeBean.class);
    }

    /**
     * 数据查询，返回Page
     * @param field 查询字段
     * @param value 查询值
     * @return AggregatedPage<EmployeeBean>
     */
    @Override
    public AggregatedPage<EmployeeBean> queryMatchPage(String field, String value) {
        MatchQueryBuilder builder = QueryBuilders.matchQuery(field, value);
        SearchQuery searchQuery = new NativeSearchQuery(builder).setPageable(PageRequest.of(0, 100));
        AggregatedPage<EmployeeBean> page = restTemplate.queryForPage(searchQuery, EmployeeBean.class);

        long totalElements = page.getTotalElements(); // 总记录数
        int totalPages = page.getTotalPages();  // 总页数
        int pageNumber = page.getPageable().getPageNumber(); // 当前页号
        List<EmployeeBean> beanList = page.toList();  // 当前页数据集
        Set<EmployeeBean> beanSet = page.toSet();  // 当前页数据集
        return page;
    }
```

QueryBuilders对象是用于创建查询方法的，支持多种查询类型，常用的查询API包括以下方法：

```
/**
     * 关键字匹配查询
     *
     * @param name 字段的名称
     * @param value 查询值
     */
    public static TermQueryBuilder termQuery(String name, String value) {
        return new TermQueryBuilder(name, value);
    }

    public static TermQueryBuilder termQuery(String name, int value) {
        return new TermQueryBuilder(name, value);
    }

    public static TermQueryBuilder termQuery(String name, long value) {
        return new TermQueryBuilder(name, value);
    }

    public static TermQueryBuilder termQuery(String name, float value) {
        return new TermQueryBuilder(name, value);
    }

    public static TermQueryBuilder termQuery(String name, double value) {
        return new TermQueryBuilder(name, value);
    }

    public static TermQueryBuilder termQuery(String name, boolean value) {
        return new TermQueryBuilder(name, value);
    }

    public static TermQueryBuilder termQuery(String name, Object value) {
        return new TermQueryBuilder(name, value);
    }

    /**
     * 关键字查询，同时匹配多个关键字
     *
     * @param name   字段名称
     * @param values  查询值
     */
    public static TermsQueryBuilder termsQuery(String name, String... values) {
        return new TermsQueryBuilder(name, values);
    }

    /**
     * 创建一个匹配多个关键字的查询，返回boolean
     *
     * @param fieldNames 字段名称
     * @param text           查询值
     */
    public static MultiMatchQueryBuilder multiMatchQuery(Object text, String... fieldNames) {
        return new MultiMatchQueryBuilder(text, fieldNames); // BOOLEAN is the default
    }

    /**
     * 关键字，精确匹配
     *
     * @param name 字段名称
     * @param text    查询值
     */
    public static MatchQueryBuilder matchQuery(String name, Object text) {
        return new MatchQueryBuilder(name, text);
    }

    /**
     * 关键字范围查询（后面跟范围条件）
     *
     * @param name 字段名称
     */
    public static RangeQueryBuilder rangeQuery(String name) {
        return new RangeQueryBuilder(name);
    }

    /**
     * 判断字段是否有值
     *
     * @param name 字段名称
     */
    public static ExistsQueryBuilder existsQuery(String name) {
        return new ExistsQueryBuilder(name);
    }

    /**
     * 模糊查询
     *
     * @param name  字段名称
     * @param value  查询值
     */
    public static FuzzyQueryBuilder fuzzyQuery(String name, String value) {
        return new FuzzyQueryBuilder(name, value);
    }

    /**
     * 组合查询对象，可以同时引用上面的所有查询对象
     */
    public static BoolQueryBuilder boolQuery() {
        return new BoolQueryBuilder();
    }
```







# MySQL

## 架构



**连接层**：最上层是一些客户端和连接服务。**主要完成一些类似于连接处理、授权认证、及相关的安全方案**。在该层上引入了线程池的概念，为通过认证安全接入的客户端提供线程。同样在该层上可以实现基于SSL的安全链接。服务器也会为安全接入的每个客户端验证它所具有的操作权限。

**服务层**：第二层服务层，主要完成大部分的核心服务功能， 包括查询解析、分析、优化、缓存、以及所有的内置函数，所有跨存储引擎的功能也都在这一层实现，包括触发器、存储过程、视图等

**引擎层**：第三层存储引擎层，存储引擎真正的负责了MySQL中数据的存储和提取，服务器通过API与存储引擎进行通信。不同的存储引擎具有的功能不同，这样我们可以根据自己的实际需要进行选取

**存储层**：第四层为数据存储层，主要是将数据存储在运行于该设备的文件系统之上，并完成与存储引擎的交互


查询流程：

![img](https://raw.githubusercontent.com/a1254898873/images/master/1734bff309fc730f%7Etplv-t2oaga2asx-watermark.awebp)





## 存储引擎



|<span style="display:inline-block;width:100px">对比项</span>   | MyISAM                                                   | InnoDB                                                       |
| -------- | -------------------------------------------------------- | ------------------------------------------------------------ |
| 主外键   | 不支持                                                   | 支持                                                         |
| 事务     | 不支持                                                   | 支持                                                         |
| 行表锁   | 表锁，即使操作一条记录也会锁住整个表，不适合高并发的操作 | 行锁,操作时只锁某一行，不对其它行有影响，适合高并发的操作    |
| 缓存     | 只缓存索引，不缓存真实数据                               | 不仅缓存索引还要缓存真实数据，对内存要求较高，而且内存大小对性能有决定性的影响 |
| 表空间   | 小                                                       | 大                                                           |
| 关注点   | 性能                                                     | 事务                                                         |
| 默认安装 | 是                                                       | 是                                                           |



1. InnoDB 支持事务，MyISAM 不支持事务。这是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一；
2. InnoDB 最小的锁粒度是行锁，MyISAM 最小的锁粒度是表锁。一个更新语句会锁住整张表，导致其他查询和更新都会被阻塞，因此并发访问受限。这也是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一





## 数据类型

CHAR 和 VARCHAR 的选择

- MyISAM：建议使用固定长度的数据列替代可变长度的数据列，也就是 CHAR
- MEMORY：使用固定长度进行处理、CHAR 和 VARCHAR 都会被当作 CHAR 处理
- InnoDB：建议使用 VARCHAR 类型



TEXT 与 BLOB

一般在保存较少的文本的时候，我们会选择 CHAR 和 VARCHAR，在保存大数据量的文本时，我们往往选择 TEXT 和 BLOB；TEXT 和 BLOB 的主要差别是 BLOB 能够保存二进制数据；而 TEXT 只能保存字符数据

- 非必要的时候不要检索 BLOB 和 TEXT 索引
- 把 BLOB 或 TEXT 列分离到单独的表中。



日期时间选择

日期格式必须为 yyyy-mm-dd

日期所在的列数据类型为datetime





## 索引

### 本质

索引的本质是一种排好序的数据结构。



### 分类

1、Hash 索引

Hash 索引是比较常见的一种索引，他的单条记录查询的效率很高，时间复杂度为1。但是，Hash索引并不是最常用的数据库索引类型，尤其是我们常用的Mysql Innodb引擎就是不支持hash索引的。主要有以下原因：Hash索引适合精确查找，但是范围查找不适合



2、二叉树

（1）当数据量大的时候，树的高度会比较高，数据量大的时候，查询会比较慢；

（2）每个节点只存储一个记录，可能导致一次查询有很多次磁盘IO；



3、B树

B树被作为实现索引的数据结构被创造出来，是因为它能够完美的利用“局部性原理”。

（1）由于是m分叉的，高度能够大大降低；

（2）每个节点可以存储j个记录，如果将节点大小设置为页大小，例如4K，能够充分的利用预读的特性，极大减少磁盘IO；



4、B+树

（1）范围查找，定位min与max之后，中间叶子节点，就是结果集，不用中序回溯；

*画外音：范围查询在SQL中用得很多，这是B+树比B树最大的优势。*

（2）叶子节点存储实际记录行，记录行相对比较紧密的存储，适合大数据量磁盘存储；非叶子节点存储记录的PK，用于查询加速，适合内存存储；

（3）非叶子节点，不存储实际记录，而只存储记录的KEY的话，那么在相同内存的情况下，B+树能够存储更多索引；



### 设计原则



- 选择索引位置，选择索引最合适的位置是出现在 where 语句中的列，而不是 select 关键字后的选择列表中的列。
- 需要排序的列加索引
- 用来连接的列加索引
- 选择使用唯一索引，顾名思义，唯一索引的值是唯一的，可以更快速的确定某条记录，例如学生的学号就适合使用唯一性索引，而学生的性别则不适合使用，因为不管搜索哪个值，都差不多有一半的行。
- 为经常使用的字段建立索引，如果某个字段经常用作查询条件，那么这个字段的查询速度在极大程度上影响整个表的查询速度，因此为这样的字段建立索引，可以提高整个表的查询速度。
- 不要过度索引，限制索引数目，索引的数目不是越多越好，每个索引都会占据磁盘空间，索引越多，需要的磁盘空间就越大。
- 尽量使用前缀索引，如果索引的值很长，那么查询速度会受到影响，这个时候应该使用前缀索引，对列的某几个字符进行索引，可以提高检索效率。
- 利用最左前缀，在创建一个 n 列的索引时，实际上是创建了 MySQL 可利用的 n 个索引。多列索引可以起到几个索引的作用，利用索引最左边的列来匹配行，这样的列称为最左前缀。
- 对于使用 InnoDB 存储引擎的表来说，记录会按照一定的顺序保存。如果有明确的主键定义，那么会按照主键的顺序进行保存；如果没有主键，但是有唯一索引，那么就按照唯一索引的顺序进行保存。如果既没有主键又没有唯一索引，那么表中会自动生成一个内部列，按照这个列的顺序进行保存。一般来说，使用主键的顺序是最快的
- 删除不再使用或者很少使用的索引



### 索引失效

1、查询条件包含or，可能导致索引失效



2、如何字段类型是字符串，where时一定用引号" "括起来，否则索引失效



3、like通配符可能导致索引失效。

不是用了like通配符，索引一定失效，而是like查询是以%开头，才会导致索引失效。



4、联合索引，查询时的条件列不是联合索引中的第一个列，索引失效。

- 当我们创建一个联合索引的时候，如(k1,k2,k3)，相当于创建了（k1）、(k1,k2)和(k1,k2,k3)三个索引，这就是最左匹配原则。
- 联合索引不满足最左原则，索引一般会失效，但是这个还跟Mysql优化器有关的。



5、在索引列上使用mysql的内置函数，索引失效。



6、对索引列运算（如，+、-、*、/），索引失效。



7、索引字段上使用（！= 或者 < >，not in）时，可能会导致索引失效。



8、索引字段上使用is null， is not null，可能导致索引失效。



9、左连接查询或者右连接查询查询关联的字段编码格式不一样，可能导致索引失效。



10、mysql估计使用全表扫描要比使用索引快,则不使用索引。

- 当表的索引被查询，会使用最好的索引，除非优化器使用全表扫描更有效。优化器优化成全表扫描取决与使用最好索引查出来的数据是否超过表的30%的数据。
- 不要给'性别'等增加索引。如果某个数据列里包含了均是"0/1"或“Y/N”等值，即包含着许多重复的值，就算为它建立了索引，索引效果不会太好，还可能导致全表扫描。



## 事务

### 特性

![img](https://raw.githubusercontent.com/a1254898873/images/master/1712b5213446a402%7Etplv-t2oaga2asx-watermark.awebp)

**原子性：** 事务作为一个整体被执行，包含在其中的对数据库的操作要么全部都执行，要么都不执行。

**一致性：** 指在事务开始之前和事务结束以后，数据不会被破坏，假如A账户给B账户转10块钱，不管成功与否，A和B的总金额是不变的。

**隔离性：** 多个事务并发访问时，事务之间是相互隔离的，一个事务不应该被其他事务干扰，多个并发事务之间要相互隔离。。

**持久性：** 表示事务完成提交后，该事务对数据库所作的操作更改，将持久地保存在数据库之中。



### 异常

1、脏读

脏读指的是读到了其他事务未提交的数据，未提交意味着这些数据可能会回滚，也就是可能最终不会存到数据库中，也就是不存在的数据。读到了并一定最终存在的数据，这就是脏读。

2、不可重复读

两次读到的数据不一样，重点在于修改

 3、幻读

同样的条件，第一次和第二次读出来的记录数不一样，重点在于新增或者删除



## 事务隔离级别

| 隔离级别 | 脏读   | 不可重复读 | 幻读   |
| -------- | ------ | ---------- | ------ |
| 读未提交 | 可能   | 可能       | 可能   |
| 读提交   | 不可能 | 可能       | 可能   |
| 可重复读 | 不可能 | 不可能     | 可能   |
| 串行化   | 不可能 | 不可能     | 不可能 |

首先说读未提交，它是性能最好，也可以说它是最野蛮的方式，因为它压根儿就不加锁，所以根本谈不上什么隔离效果，可以理解为没有隔离。

再来说串行化。读的时候加共享锁，也就是其他事务可以并发读，但是不能写。写的时候加排它锁，其他事务不能并发写也不能并发读。

最后说读提交和可重复读。这两种隔离级别是比较复杂的，既要允许一定的并发，又想要兼顾的解决问题。





## 锁

### 锁的粒度

![img](https://raw.githubusercontent.com/a1254898873/images/master/ecdd4cb96b014434b5cad61d94dc5f8b%7Etplv-k3u1fbpfcp-watermark.awebp)

读锁是共享锁，多个读操作不受影响

写锁是排它锁，不让读和写





### 乐观锁和悲观锁

乐观锁不是数据库自带的，需要我们自己去实现。乐观锁是指操作数据库时(更新操作)，想法很乐观，认为这次的操作不会导致冲突，在操作数据时，并不进行任何其他的特殊处理（也就是不加锁），而在进行更新后，再去判断是否有冲突了。

通常实现是这样的：在表中的数据进行操作时(更新)，先给数据表加一个版本(version)字段，每操作一次，将那条记录的版本号加1。也就是先查询出那条记录，获取出version字段,如果要对那条记录进行操作(更新),则先判断此刻version的值是否与刚刚查询出来时的version的值相等，如果相等，则说明这段期间，没有其他程序对其进行操作，则可以执行更新，将version字段的值加1；如果更新时发现此刻的version值与刚刚获取出来的version的值不相等，则说明这段期间已经有其他程序对其进行操作了，则不进行更新操作。

与乐观锁相对应的就是悲观锁了。悲观锁就是在操作数据时，认为此操作会出现数据冲突，所以在进行每次操作时都要通过获取锁才能进行对相同数据的操作。共享锁和排它锁是悲观锁的不同的实现，它俩都属于悲观锁的范畴。









## MVCC

MVCC，即Multi-Version Concurrency Control （多版本并发控制）。它是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问，在编程语言中实现事务内存。

数据库隔离级别读已提交、可重复读 都是基于MVCC实现的，相对于加锁简单粗暴的方式，它用更好的方式去处理读写冲突，能有效提高数据库并发性能。

它实现读取数据不用加锁，可以让读取数据同时修改。修改数据时同时可读取。







## 日志

1、redo log

当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log里面，并更新内存，这个时候就算完成了。同时，InnoDB引擎会在适当的时候，将这个操作记录更新到磁盘里面。



2、bin log

binlog用于记录数据库执行的写入性操作(不包括查询)信息，以二进制的形式保存在磁盘中。binlog是mysql的逻辑日志，并且由Server层进行记录，使用任何存储引擎的mysql数据库都会记录binlog日志。

应用

- 主从复制：在Master端开启binlog，然后将binlog发送到各个Slave端，Slave端重放binlog从而达到主从数据一致。
- 数据恢复：通过使用mysqlbinlog工具来恢复数据。



3、undo log

undo log主要记录了数据的逻辑变化，比如一条INSERT语句，对应一条DELETE的undo log，对于每个UPDATE语句，对应一条相反的UPDATE的undo log，这样在发生错误时，就能回滚到事务之前的数据状态。





## SQL

### 一、优化

1、避免使用select *

sql语句查询时，只查需要用到的列，多余的列根本无需查出来。



2、用union all代替union

我们都知道sql语句使用union关键字后，可以获取排重后的数据。

而如果使用union all关键字，可以获取所有数据，包含重复的数据。

除非是有些特殊的场景，比如union all之后，结果集中出现了重复数据，而业务场景中是不允许产生重复数据的，这时可以使用union。



3、小表驱动大表

小表驱动大表，也就是说用小表的数据集驱动大表的数据集。

假如有order和user两张表，其中order表有10000条数据，而user表有100条数据。

这时如果想查一下，所有有效的用户下过的订单列表。

可以使用in关键字实现：

```
select * from order
where user_id in (select id from user where status=1)
```

也可以使用exists关键字实现：

```
select * from order
where exists (select 1 from user where order.user_id = user.id and status=1)
```

前面提到的这种业务场景，使用in关键字去实现业务需求，更加合适。

为什么呢？

因为如果sql语句中包含了in关键字，则它会优先执行in里面的`子查询语句`，然后再执行in外面的语句。如果in里面的数据量很少，作为条件查询速度更快。

而如果sql语句中包含了exists关键字，它优先执行exists左边的语句（即主查询语句）。然后把它作为条件，去跟右边的语句匹配。如果匹配上，则可以查询出数据。如果匹配不上，数据就被过滤掉了。

这个需求中，order表有10000条数据，而user表有100条数据。order表是大表，user表是小表。如果order表在左边，则用in关键字性能更好。

总结一下：

- in 适用于左边大表，右边小表。
- exists 适用于左边小表，右边大表。

不管是用in，还是exists关键字，其核心思想都是用小表驱动大表。



4、批量操作

我们在代码中，每次远程请求数据库，是会消耗一定性能的。而如果我们的代码需要请求多次数据库，才能完成本次业务功能，势必会消耗更多的性能。

我们可以提供一个批量插入数据的方法

```
insert into order(id,code,user_id) 
values(123,'001',100),(124,'002',100),(125,'003',101);
```



5、多用limit



6、in中值太多



7、用连接查询代替子查询

子查询语句的优点是简单，结构化，如果涉及的表数量不多的话。

但缺点是mysql执行子查询时，需要创建临时表，查询完毕后，需要再删除这些临时表，有一些额外的性能消耗。



### 二、常用的sql

1、排序

```
select * from table order by desc/asc
```

2、去重

```
select distinct(column) from table...
```



3、group by与having区别

使用group by的sql语句，select后的字段只能是group by后的字段，如果需要展示其他字段数据，需要给该列使用聚合函数，否则默认展示分组后的第一行数据。

```
select sum(price),order_id from order where price>100 group by order_id
```

having是对分组后的数据进行过滤

```
select sum(price),order_id from order where price>100 group by order_id HAVING sum(price)>1000
```

SQL语句执行顺序：from--where--group by--having--select--order by



4、嵌套查询

```
select user_name,iphone from user where id in (select user_id from order)
```

嵌套的语句可以在select之后，from之后，where条件之后





## 三大范式

### 第一范式

列都是不可再分，第一范式的目标是确保每列的原子性，每列都是不可再分的最小数据单元

违反第一范式

![img](https://raw.githubusercontent.com/a1254898873/images/master/2d525382958340de95f5e5c1750ecb2f%7Etplv-k3u1fbpfcp-watermark.awebp)

符合第一范式

![img](https://raw.githubusercontent.com/a1254898873/images/master/bd0d0a8e0dd84abba3244a2616a536db%7Etplv-k3u1fbpfcp-watermark.awebp)





### 第二范式

首先满足第一范式，并且表中非主键列不存在对主键不依赖或者部分依赖，确保每个列都和主键相关。一般因为是存在多个主键，或者存在复合主键，因此需要拆表。

存在复合主键（学号，学科），而学科学分却只依赖分部主键-学科，不符合第二范式

![img](https://raw.githubusercontent.com/a1254898873/images/master/118de63ad8424fe196d4f0d31be60ed9%7Etplv-k3u1fbpfcp-watermark.awebp)

第二范式的正确示范

![img](https://raw.githubusercontent.com/a1254898873/images/master/dedaecffb32b44adaa51307a80099fcd%7Etplv-k3u1fbpfcp-watermark.awebp)

![img](https://raw.githubusercontent.com/a1254898873/images/master/7d0c578f9edf4ce98e48683ed65c98b2%7Etplv-k3u1fbpfcp-watermark.awebp)



### 第三范式

第三范式在第二范式基础上，消除传递依赖。







# Redis

## redis数据类型

### 1、string

sds数据结构，采用空间预分配和惰性空间释放来提升效率，缺点就是耗费内存。

```
struct sdshdr {
    int len; //长度
    int free; //剩余空间
    char buf[]; //字符串数组
};
```

简单使用举例: set key value、get key等

用场景：共享session、分布式锁、验证码、缓存、计数器。

空间预分配：当一个sds被修改成更长的buf时，除了会申请本身需要的内存外，还会额外申请一些空间。

惰性空间：当一个sds被修改成更短的buf时，并不会把多余的内存还回去，而是会保存起来。

Redis为什么选择SDS结构？

SDS中，O(1)时间复杂度，就可以获取字符串长度；而C 字符串，需要遍历整个字符串，时间复杂度为O(n)





### 2、hash

不仅仅是数据类型为hash的才用到hash结构，redis本身所有的k、v就是一个大hash。例如我们经常用的set key value，key就是hash的键，value就是hash的值。

```
struct dict {
    ...
    dictht ht[2]; //哈希表
    rehashidx == -1 //rehash使用，没有rehash的时候为-1
}
```

简单使用举例：hset key field value 、hget key field

应用场景：购物车

hash冲突：采用单向链表的方式解决hash冲突，新的冲突元素会被放到链表的表头。



### 3、list

底层是一个双向链表结构，所以我们可以向链表的两端添加元素，时间复杂度是O(1)

```
struct listNode {
    struct listNode * prev; //前置节点
    struct listNode * next; //后置节点
    void * value;//节点的值
};
```

简单实用举例： lpush key value [value ...] 、lrange key start end

应用场景： 消息队列，文章列表

```
lpush+lpop=Stack（栈）
lpush+rpop=Queue（队列）
lpsh+ltrim=Capped Collection（有限集合）
lpush+brpop=Message Queue（消息队列）
```





### 4、set

```
struct intset {
    uint32_t encoding;//编码方式
    uint32_t length;//集合包含的元素数量
    int8_t contents[];//保存元素的数组
};
```

简单使用举例：sadd key element [element ...]、smembers key

应用场景： 抽奖、点赞、收藏、关注、商品筛选



### 5、zset

```
struct zskiplistNode {
    struct zskiplistLevel {
        struct zskiplistNode *forward;//前进指针
        unsigned int span;//跨度
    } level[];
    struct zskiplistNode *backward;//后退指针
    double score;//分值
    robj *obj; // 成员对象
};
```

应用场景：排行榜



## 底层数据结构

![img](https://raw.githubusercontent.com/a1254898873/images/master/a63c298d256b436ea36112c6aecc7404%7Etplv-k3u1fbpfcp-watermark.awebp)

String：如果存储数字的话，是用int类型的编码;如果存储非数字，小于等于39字节的字符串，是embstr；大于39个字节，则是raw编码。

List：如果列表的元素个数小于512个，列表每个元素的值都小于64字节（默认），使用ziplist编码，否则使用linkedlist编码

Hash：哈希类型元素个数小于512个，所有值小于64字节的话，使用ziplist编码,否则使用hashtable编码。

Set：如果集合中的元素都是整数且元素个数小于512个，使用intset编码，否则使用hashtable编码。

Zset：当有序集合的元素个数小于128个，每个元素的值小于64字节时，使用ziplist编码，否则使用skiplist（跳跃表）编码



## Redis特点

1、基于内存存储实现

2、采用单进程单线程模型

3、采用了IO多路复用

- 多路 ：多个网络连接
- 复用：复用同一个线程。







# Minio

## 配置文件

```
minio:
  endpoint: http://172.16.3.28:10000
  accessKey: admin
  secretKey: 12345678
  bucketName: aaa
```

```
spring:
  # 配置文件上传大小限制
  servlet:
    multipart:
      max-file-size: 100MB
      max-request-size: 100MB

```



## 配置类

```

@Data
@Component
@ConfigurationProperties(prefix = "minio")
public class MinioPropertiesConfig {

    /**
     * 端点
     */
    private String endpoint;
    /**
     * 用户名
     */
    private String accessKey;
    /**
     * 密码
     */
    private String secretKey;

    /**
     * 桶名称
     */
    private String bucketName;
}

```

```

@Configuration
@EnableConfigurationProperties(MinioPropertiesConfig.class)
public class MinioConfig {

    @Resource
    private MinioPropertiesConfig minioPropertiesConfig;


    /**
     * 初始化 MinIO 客户端
     */
    @Bean
    public MinioClient minioClient() {
        MinioClient minioClient = MinioClient.builder()
                .endpoint(minioPropertiesConfig.getEndpoint())
                .credentials(minioPropertiesConfig.getAccessKey(), minioPropertiesConfig.getSecretKey())
                .build();
        return minioClient;
    }
}

```



## 工具类

```

@Component
public class MinioUtil {

    @Value("${minio.bucketName}")
    private String bucketName;

    @Autowired
    private MinioClient minioClient;

    /**
     * description: 判断bucket是否存在，不存在则创建
     *
     * @return: void
     * @author: weirx
     * @time: 2021/8/25 10:20
     */
    public void existBucket(String name) {
        try {
            boolean exists = minioClient.bucketExists(BucketExistsArgs.builder().bucket(name).build());
            if (!exists) {
                minioClient.makeBucket(MakeBucketArgs.builder().bucket(name).build());
            }
        } catch (Exception e) {
            e.printStackTrace();
        }
    }

    /**
     * description: 上传文件
     *
     * @param multipartFile
     * @return: java.lang.String
     * @author: weirx
     * @time: 2021/8/25 10:44
     */
    public List<String> upload(MultipartFile[] multipartFile) {
        List<String> names = new ArrayList<>(multipartFile.length);
        for (MultipartFile file : multipartFile) {
            String fileName = file.getOriginalFilename();
            String[] split = fileName.split("\\.");
            if (split.length > 1) {
                fileName = split[0] + "_" + System.currentTimeMillis() + "." + split[1];
            } else {
                fileName = fileName + System.currentTimeMillis();
            }
            InputStream in = null;
            try {
                in = file.getInputStream();
                minioClient.putObject(PutObjectArgs.builder()
                        .bucket(bucketName)
                        .object(fileName)
                        .stream(in, in.available(), -1)
                        .contentType(file.getContentType())
                        .build()
                );
            } catch (Exception e) {
                e.printStackTrace();
            } finally {
                if (in != null) {
                    try {
                        in.close();
                    } catch (IOException e) {
                        e.printStackTrace();
                    }
                }
            }
            names.add(fileName);
        }
        return names;
    }

    /**
     * description: 下载文件
     *
     * @param fileName
     * @return: org.springframework.http.ResponseEntity<byte [ ]>
     * @author: weirx
     * @time: 2021/8/25 10:34
     */
    public ResponseEntity<byte[]> download(String fileName) {
        ResponseEntity<byte[]> responseEntity = null;
        InputStream in = null;
        ByteArrayOutputStream out = null;
        try {
            in = minioClient.getObject(GetObjectArgs.builder().bucket(bucketName).object(fileName).build());
            out = new ByteArrayOutputStream();
            IOUtils.copy(in, out);
            //封装返回值
            byte[] bytes = out.toByteArray();
            HttpHeaders headers = new HttpHeaders();
            try {
                headers.add("Content-Disposition", "attachment;filename=" + URLEncoder.encode(fileName, Constants.UTF_8));
            } catch (UnsupportedEncodingException e) {
                e.printStackTrace();
            }
            headers.setContentLength(bytes.length);
            headers.setContentType(MediaType.APPLICATION_OCTET_STREAM);
            headers.setAccessControlExposeHeaders(Arrays.asList("*"));
            responseEntity = new ResponseEntity<byte[]>(bytes, headers, HttpStatus.OK);
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            try {
                if (in != null) {
                    try {
                        in.close();
                    } catch (IOException e) {
                        e.printStackTrace();
                    }
                }
                if (out != null) {
                    out.close();
                }
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
        return responseEntity;
    }
}

```

