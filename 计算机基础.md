# Data Structures

## Linear Data Structure 

### Arrays

![array](https://raw.githubusercontent.com/a1254898873/images/master/202203311551699.png)

An array is a collection of items stored at contiguous memory locations. 

It is easier to calculate the position of each element by simply adding an offset to a base value.

But you canâ€™t change the size.

And insertion and deletion are costly.





### Linked List

![linkedlist](https://raw.githubusercontent.com/a1254898873/images/master/202203311551183.png)

Unlike arrays, linked list elements are not stored at a contiguous location; the elements are linked using pointers.

It has dynamic size. And it is easy to delete or insert element .

But random access is not allowed and pointers need extra memory space .



There are three common types of Linked List.

#### (1) Singly Linked List

It is the most common. Each node has data and a pointer to the next node.

<img src="https://raw.githubusercontent.com/a1254898873/images/master/202204022030799.png" alt="singly linked list" style="zoom:80%;" />



#### (2) Doubly Linked List

We add a pointer to the previous node in a doubly-linked list. Thus, we can go in either direction: forward or backward.

<img src="https://raw.githubusercontent.com/a1254898873/images/master/202204022030800.png" alt="doubly linked list" style="zoom:80%;" />



#### (3) Circular Linked List

A circular linked list is a variation of a linked list in which the last element is linked to the first element.

<img src="https://raw.githubusercontent.com/a1254898873/images/master/202204022030801.png" alt="circular linked list" style="zoom: 67%;" />







### Stack 

<img src="https://raw.githubusercontent.com/a1254898873/images/master/202203311600682.png" alt="img" style="zoom:80%;" />

It follow the principle of FILO. It means the last element inserted into the stack is removed first .

- Push: Add an element to the top of a stack
- Pop: Remove an element from the top of a stack
- IsEmpty: Check if the stack is empty
- IsFull: Check if the stack is full
- Peek: Get the value of the top element without removing it





### Queue 

![img](https://raw.githubusercontent.com/a1254898873/images/master/202203311609249.png)

It follow the principle of FIFO. It means the first  element inserted into the stack is removed first .

- **Enqueue**: Add an element to the end of the queue
- **Dequeue**: Remove an element from the front of the queue
- **IsEmpty**: Check if the queue is empty
- **IsFull**: Check if the queue is full
- **Peek**: Get the value of the front of the queue without removing it



There are four different types of queues.

#### (1) Simple Queue

In a simple queue, insertion takes place at the rear and removal occurs at the front. It strictly follows the FIFO (First in First out) rule.

<img src="https://raw.githubusercontent.com/a1254898873/images/master/202204021757945.png" alt="Simple queue " style="zoom:80%;" />

#### (2) Circular Queue

In a circular queue, the last element points to the first element making a circular link.

<img src="https://raw.githubusercontent.com/a1254898873/images/master/202204021757160.png" alt="Circular queue " style="zoom:80%;" />

#### (3) Priority Queue

A priority queue is a special type of queue in which each element is associated with a priority and is served according to its priority. If elements with the same priority occur, they are served according to their order in the queue.

<img src="https://raw.githubusercontent.com/a1254898873/images/master/202204021750449.png" alt="Priority queue" style="zoom: 67%;" />



#### (4) Double Ended Queue

In a double ended queue, insertion and removal of elements can be performed from either from the front or rear. Thus, it does not follow the FIFO (First In First Out) rule.

<img src="https://raw.githubusercontent.com/a1254898873/images/master/202204021749764.png" alt="Double ended queue" style="zoom:80%;" />







## Tree Data Structure

Trees are hierarchical data structures.



### Binary Tree

<img src="https://raw.githubusercontent.com/a1254898873/images/master/202204031917021.png" alt="Binary Tree" style="zoom:67%;" />

A binary tree is a tree data structure in which each parent node can have at most two children. Each node of a binary tree consists of three items:

- data item
- address of left child
- address of right child





### Binary Search Tree

Binary search tree is a data structure that quickly allows us to maintain a sorted list of numbers.

The properties that separate a binary search tree from a regular binary tree is

1. All nodes of left subtree are less than the root node
2. All nodes of right subtree are more than the root node
3. Both subtrees of each node are also Binary Search Tree





### AVL Tree

<img src="https://raw.githubusercontent.com/a1254898873/images/master/202204031917022.png" alt="avl tree" style="zoom:50%;" />

AVL tree is a self-balancing binary search tree in which each node maintains extra information called a balance factor whose value is either -1, 0 or +1.





### B-tree

<img src="https://raw.githubusercontent.com/a1254898873/images/master/202204031916735.png" alt="B-tree example" style="zoom:50%;" />

B-tree is a special type of self-balancing search tree in which each node can contain more than one key and can have more than two children.





### B+ Tree

<img src="https://raw.githubusercontent.com/a1254898873/images/master/202204031916569.png" alt="Multilevel Indexing using B+ tree" style="zoom: 50%;" />

A B+ tree is an advanced form of a self-balancing tree in which all the values are present in the leaf level.

An important concept to be understood before learning B+ tree is multilevel indexing.





### Red-Black Tree

<img src="https://cdn.programiz.com/sites/tutorial2program/files/red-black-tree_0.png" alt="red-black tree" style="zoom:50%;" />

Red-Black tree is a self-balancing binary search tree in which each node contains an extra bit for denoting the color of the node, either red or black.







## Graph Data Stucture

A graph data structure is a collection of nodes that have data and are connected to other nodes.



### Adjacency Matrix

<img src="https://raw.githubusercontent.com/a1254898873/images/master/202204031916223.png" alt="graph adjacency matrix for sample graph shows that the value of matrix element is 1 for the row and column that have an edge and 0 for row and column that don't have an edge" style="zoom:50%;" />

An adjacency matrix is a 2D array of V x V vertices. Each row and column represent a vertex.





### Adjacency List

<img src="https://raw.githubusercontent.com/a1254898873/images/master/202204030059936.png" alt="adjacency list representation represents graph as array of linked lists where index represents the vertex and each element in linked list represents the edges connected to that vertex" style="zoom:50%;" />

An adjacency list represents a graph as an array of linked lists.

The index of the array represents a vertex and each element in its linked list represents the other vertices that form an edge with the vertex.





## Hashing Data Structure

<img src="https://raw.githubusercontent.com/a1254898873/images/master/202204031915892.png" alt="Hashing Data Structure" style="zoom:50%;" />



The Hash table data structure stores elements in key-value pairs where

- **Key**- unique integer that is used for indexing the values
- **Value** - data that are associated with keys.

In a hash table, a new index is processed using the keys. And, the element corresponding to that key is stored in the index. This process is called hashing.







## sorting algorithm 

### Bubble Sort

Bubble sort is a sorting algorithm that compares two adjacent elements and swaps them until they are not in the intended order.





### Selection Sort

Selection sort is a sorting algorithm that selects the smallest element from an unsorted list in each iteration and places that element at the beginning of the unsorted list.





### Insertion Sort

Insertion sort is a sorting algorithm that places an unsorted element at its suitable place in each iteration.





### Merge Sort

Merge Sort is one of the most popular sorting algorithms that is based on the principle of Divide and Conquer Algorithm.

Here, a problem is divided into multiple sub-problems. Each sub-problem is solved individually. Finally, sub-problems are combined to form the final solution.





### Quick Sort 

Quick Sort is a Divide and Conquer algorithm. It picks an element as pivot and partitions the given array around the picked pivot. 





### Heap Sort

Heap sort is based on Binary Heap data structure. It is similar to selection sort where we first find the minimum element and place the minimum element at the beginning.





### Shell Sort

Shell sort is a generalized version of the insertion sort algorithm. It first sorts elements that are far apart from each other and successively reduces the interval between the elements to be sorted.





### Bucket Sort

Bucket Sort is a sorting algorithm that divides the unsorted array elements into several groups called buckets. Each bucket is then sorted by using any of the suitable sorting algorithms or recursively applying the same bucket algorithm.

Finally, the sorted buckets are combined to form a final sorted array.









# Computer Network

## Physical Layer

The physical layer is the first and lowest layer of the Open System Interconnection Model (OSI Model.)

The physical layer deals with bit-level transmission between different devices and supports electrical or mechanical interfaces connecting to the physical medium for synchronized communication.





## Data Link layer

The data link layer is the protocol layer in a program that handles the moving of data into and out of a physical link in a network. The data link layer is Layer 2 in the Open Systems Interconnection (OSI) architecture model for a set of telecommunication protocols.

Data bits are encoded, decoded and organized in the data link layer, before they are transported as frames between two adjacent nodes on the same LAN or WAN. 



ARP ï¼šAddress Resolution Protocol (ARP) is a protocol or procedure that connects an ever-changing Internet Protocol (IP) address to a fixed physical machine address, also known as a media access control (MAC) address, in a local-area network (LAN). 





## Network Layer

The network layer is the third level (Layer 3) of the Open Systems Interconnection Model (OSI Model) and the layer that provides data routing paths for network communication. Data is transferred to the receiving device in the form of packets via logical network paths in an ordered format controlled by the network layer.



Internet Protocol ï¼šInternet Protocol provides unreliable, connectionless packet delivery for the Internet.





## Transport Layer

The transport layer is the fourth layer in the open systems interconnection (OSI) network model.

The transport layer provides a total end-to-end solution for reliable communications.



TCP Connection Establishment ï¼ˆ3-Way Handshake Processï¼‰ï¼š

1. In the first step, the client wants to establish a connection with a server, so it sends a segment with SYN(Synchronize Sequence Number) which informs the server that the client is likely to start communication and with what sequence number it starts segments with
2. Server responds to the client request with SYN-ACK signal bits set. Acknowledgement(ACK) signifies the response of the segment it received and SYN signifies with what sequence number it is likely to start the segments with
3. In the final part client acknowledges the response of the server and they both establish a reliable connection with which they will start the actual data transfer

![img](https://raw.githubusercontent.com/a1254898873/images/master/202204031445116.png)



TCP Connection Terminationï¼ˆ4-Way Handshake Processï¼‰ï¼š

1. Client send finish datagram to the server, indicated that client will close the transmission from client to server. This is called **active close**. (FIN=1, seq=u)

2. Server acknowledged the FIN datagram. (ACK=1, seq=v, ack=u+1)

3. Server contiues to transmit, if the server finishs the transmission it will close transmission from server to client. This is called **passive close**.(FIN=1, ACK=1, seq=w, ack=u+1)

4. Client acknowledged the FIN datagram to the server.(ACK=1, seq=u+1, ack=w+1)

![11](https://raw.githubusercontent.com/a1254898873/images/master/202204031444310.png)





## Application layer

The application layer of the seven-layer OSI model is the top layer that approaches protocols for application interaction with the network.

With a focus on end-user services, the application layer helps to facilitate process-to-process connections over Internet protocol.



HTTP ï¼šHTTP is a protocol for fetching resources such as HTML documents. It is the foundation of any data exchange on the Web and it is a client-server protocol, which means requests are initiated by the recipient, usually the Web browser. 









# Operating Systems

## Process and Thread 

A process is a program in execution. 



### ï¼ˆ1ï¼‰process  in memory

![process](https://raw.githubusercontent.com/a1254898873/images/master/202204031918584.png)





### ï¼ˆ2ï¼‰States of Process

![process-states](https://raw.githubusercontent.com/a1254898873/images/master/202204031919544.png)

A process is in one of the following states: 

1. New: Newly Created Process (or) being-created process.
2. Ready: After creation process moves to Ready state, i.e. the 
          process is ready for execution.
3. Run: Currently running process in CPU (only one process at
        a time can be under execution in a single processor).
4. Wait (or Block): When a process requests I/O access.
5. Complete (or Terminated): The process completed its execution.
6. Suspended Ready: When the ready queue becomes full, some processes 
                    are moved to suspended ready state
7. Suspended Block: When waiting queue becomes full.



### ï¼ˆ3ï¼‰Process Schedulers

The process scheduling is the activity of the process manager that handles the removal of the running process from the CPU and the selection of another process on the basis of a particular strategy.









### ï¼ˆ4ï¼‰introduction of Threads

A thread is a path of execution within a process. A process can contain multiple threads.







## CPU Scheduling

### (1) FCFS CPU Scheduling

First in, first out (FIFO), also known as first come, first served (FCFS), is the simplest scheduling algorithm. FIFO simply queues processes in the order that they arrive in the ready queue. 

### (2) Shortest Job First

Shortest job first (SJF) or shortest job next, is a scheduling policy that selects the waiting process with the smallest execution time to execute next. 



### (3) Longest Remaining Time First

In this scheduling algorithm, we find the process with the maximum remaining time and then process it. 



### (4) Round Robin scheduling

Round Robin is a CPU scheduling algorithm where each process is assigned a fixed time slot in a cyclic way.



### (5) Multilevel Queue  CPU Scheduling

It may happen that processes in the ready queue can be divided into different classes where each class has its own scheduling needs. 





## Process Synchronization

Process Synchronization is the task of coordinating the execution of processes in a way that no two processes can have access to the same shared data and resources.



### Sections of a Program

- **Entry Section:** It is part of the process which decides the entry of a particular process.
- **Critical Section:** This part allows one process to enter and modify the shared variable.
- **Exit Section:** Exit section allows the other process that are waiting in the Entry Section, to enter into the Critical Sections. It also checks that a process that finished its execution should be removed through this Section.
- **Remainder Section:** All other parts of the Code, which is not in Critical, Entry, and Exit Section, are known as the Remainder Section.



### Rules for Critical Section

- **Mutual Exclusion:** Mutual Exclusion is a special type of binary semaphore which is used for controlling access to the shared resource. It includes a priority inheritance mechanism to avoid extended priority inversion problems. Not more than one process can execute in its critical section at one time.
- **Progress:** This solution is used when no one is in the critical section, and someone wants in. Then those processes not in their reminder section should decide who should go in, in a finite time.
- **Bound Waiting:** When a process makes a request for getting into critical section, there is a specific limit about number of processes can get into their critical section. So, when the limit is reached, the system must allow request to the process to get into its critical section.



### Deadlock

Deadlock can arise if the following four conditions hold simultaneously (Necessary Conditions) 

- Mutual Exclusion: Two or more resources are non-shareable (Only one process can use at a time) 
- Hold and Wait: A process is holding at least one resource and waiting for resources. 
- No Preemption: A resource cannot be taken from a process unless the process releases the resource. 
- Circular Wait: A set of processes are waiting for each other in circular form. 





## Memory Management

### Introduction to memory

Memories are made up of registers. Each register in the memory is one storage location. The storage location is also called as memory location. Memory locations are identified using Address. The total number of bit a memory can store is its capacity. 

A storage element is called a Cell. Each register is made up of storage element in which one bit of data is stored. The data in a memory are stored and retrieved by the process called writing and reading respectively. 



### Virtual Memory

A computer can address more memory than the amount physically installed on the system. This extra memory is actually called virtual memory and it is a section of a hard disk that's set up to emulate the computer's RAM.



(1) Paging

Paging is a memory management technique in which process address space is broken into blocks of the same size called pages.

Similarly, main memory is divided into small fixed-sized blocks of (physical) memory called frames and the size of a frame is kept the same as that of a page to have optimum utilization of the main memory and to avoid external fragmentation.



(2) Segmentation

Segmentation is a memory management technique in which each job is divided into several segments of different sizes.

Segmentation memory management works very similar to paging but here segments are of variable-length where as in paging pages are of fixed size.





## File System

A file system is a process of managing how and where data on a storage disk, which is also referred to as file management or File System. It is a logical disk component that compresses files separated into groups, which is known as directories. 